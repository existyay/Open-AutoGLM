"""
æ¨¡å‹ä¸‹è½½æ¨¡å—
æ”¯æŒä»HuggingFaceå’ŒModelScopeä¸‹è½½æ¨¡å‹
"""

import os
import sys
import json
import hashlib
import threading
import time
import subprocess
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, Callable, Dict, Any, List
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError


@dataclass
class ModelInfo:
    """æ¨¡å‹ä¿¡æ¯"""
    name: str
    repo_id: str
    source: str  # 'huggingface' or 'modelscope'
    size_gb: float
    files: List[str]
    quantization: str
    description: str


class DownloadProgress:
    """ä¸‹è½½è¿›åº¦è·Ÿè¸ª"""
    
    def __init__(self, total_size: int = 0):
        self.total_size = total_size
        self.downloaded_size = 0
        self.current_file = ""
        self.current_file_size = 0
        self.current_file_downloaded = 0
        self.speed = 0.0  # MB/s
        self.eta = 0  # ç§’
        self.status = "waiting"  # waiting, downloading, completed, error
        self.error_message = ""
        self._last_time = time.time()
        self._last_downloaded = 0
        
    def update(self, downloaded: int):
        """æ›´æ–°è¿›åº¦"""
        self.current_file_downloaded = downloaded
        current_time = time.time()
        time_diff = current_time - self._last_time
        
        if time_diff >= 1.0:  # æ¯ç§’æ›´æ–°ä¸€æ¬¡é€Ÿåº¦
            size_diff = downloaded - self._last_downloaded
            self.speed = size_diff / (1024 * 1024 * time_diff)  # MB/s
            
            if self.speed > 0:
                remaining = self.current_file_size - downloaded
                self.eta = int(remaining / (self.speed * 1024 * 1024))
            
            self._last_time = current_time
            self._last_downloaded = downloaded
            
    @property
    def percent(self) -> float:
        """è·å–å½“å‰æ–‡ä»¶ä¸‹è½½ç™¾åˆ†æ¯”"""
        if self.current_file_size <= 0:
            return 0.0
        return min(100.0, (self.current_file_downloaded / self.current_file_size) * 100)
        
    @property
    def total_percent(self) -> float:
        """è·å–æ€»ä½“ä¸‹è½½ç™¾åˆ†æ¯”"""
        if self.total_size <= 0:
            return 0.0
        total_downloaded = self.downloaded_size + self.current_file_downloaded
        return min(100.0, (total_downloaded / self.total_size) * 100)


class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨"""
    
    # é¢„å®šä¹‰æ¨¡å‹åˆ—è¡¨ - ä»…ä½¿ç”¨ModelScopeæº
    AVAILABLE_MODELS = {
        'AutoGLM-Phone-9B': ModelInfo(
            name='AutoGLM-Phone-9B',
            repo_id='ZhipuAI/AutoGLM-Phone-9B',
            source='modelscope',
            size_gb=18.0,
            files=[],
            quantization='fp16',
            description='å®˜æ–¹å®Œæ•´æ¨¡å‹ (FP16ç²¾åº¦ï¼Œéœ€è¦16GB+æ˜¾å­˜)'
        ),
    }
    
    # ModelScope Git Clone URL
    MODELSCOPE_GIT_URL = "https://www.modelscope.cn/ZhipuAI/AutoGLM-Phone-9B.git"
    
    def __init__(self, model_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        
        Args:
            model_dir: æ¨¡å‹å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ä¸º ~/.autoglm/models
        """
        if model_dir:
            self.model_dir = Path(model_dir)
        else:
            self.model_dir = Path.home() / '.autoglm' / 'models'
            
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        self.progress = DownloadProgress()
        self._stop_flag = False
        self._download_thread: Optional[threading.Thread] = None
        self._progress_callback: Optional[Callable[[DownloadProgress], None]] = None
        
    def get_model_path(self, model_name: str) -> Path:
        """è·å–æ¨¡å‹æœ¬åœ°è·¯å¾„"""
        return self.model_dir / model_name.replace('/', '_')
        
    def is_model_downloaded(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
        model_path = self.get_model_path(model_name)
        if not model_path.exists():
            return False
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„æ–‡ä»¶
        required_files = ['config.json', 'tokenizer.json']
        for f in required_files:
            if not (model_path / f).exists():
                return False
                
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æƒé‡æ–‡ä»¶
        weight_patterns = ['*.safetensors', '*.bin', '*.gguf']
        for pattern in weight_patterns:
            if list(model_path.glob(pattern)):
                return True
                
        return False
        
    def get_downloaded_models(self) -> List[str]:
        """è·å–å·²ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨"""
        downloaded = []
        if self.model_dir.exists():
            for path in self.model_dir.iterdir():
                if path.is_dir() and self.is_model_downloaded(path.name):
                    downloaded.append(path.name)
        return downloaded
        
    def download_model(self, model_name: str, 
                       progress_callback: Optional[Callable[[DownloadProgress], None]] = None,
                       use_mirror: bool = True) -> bool:
        """
        ä¸‹è½½æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼ˆä»AVAILABLE_MODELSä¸­é€‰æ‹©ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            use_mirror: æ˜¯å¦ä½¿ç”¨é•œåƒæºï¼ˆå·²å¼ƒç”¨ï¼Œç»Ÿä¸€ä½¿ç”¨ModelScopeï¼‰
            
        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        self._progress_callback = progress_callback
        self._stop_flag = False
        
        if model_name not in self.AVAILABLE_MODELS:
            self.progress.status = "error"
            self.progress.error_message = f"æœªçŸ¥æ¨¡å‹: {model_name}"
            return False
            
        model_path = self.get_model_path(model_name)
        
        try:
            self.progress.status = "downloading"
            self.progress.current_file = "å‡†å¤‡ä½¿ç”¨ Git LFS ä¸‹è½½..."
            self._notify_progress()
            
            # ç»Ÿä¸€ä½¿ç”¨ git clone ä» ModelScope ä¸‹è½½
            success = self._download_via_git_clone(model_path)
                
            if success:
                self.progress.status = "completed"
                self._notify_progress()
                return True
            else:
                return False
                
        except Exception as e:
            self.progress.status = "error"
            self.progress.error_message = str(e)
            self._notify_progress()
            return False
    
    def _download_via_git_clone(self, save_path: Path) -> bool:
        """ä½¿ç”¨ git clone ä» ModelScope ä¸‹è½½æ¨¡å‹"""
        import shutil
        
        # æ£€æŸ¥ git å’Œ git-lfs æ˜¯å¦å¯ç”¨
        try:
            result = subprocess.run(
                ['git', '--version'],
                capture_output=True, text=True, timeout=5,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0
            )
            if result.returncode != 0:
                self.progress.status = "error"
                self.progress.error_message = "Git æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Git"
                self._notify_progress()
                return False
        except (FileNotFoundError, subprocess.TimeoutExpired):
            self.progress.status = "error"
            self.progress.error_message = "Git æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Git: https://git-scm.com/downloads"
            self._notify_progress()
            return False
        
        # æ£€æŸ¥ git-lfs
        try:
            result = subprocess.run(
                ['git', 'lfs', 'version'],
                capture_output=True, text=True, timeout=5,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0
            )
            if result.returncode != 0:
                self.progress.status = "error"
                self.progress.error_message = "Git LFS æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: git lfs install"
                self._notify_progress()
                return False
        except (FileNotFoundError, subprocess.TimeoutExpired):
            self.progress.status = "error"
            self.progress.error_message = "Git LFS æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: git lfs install"
            self._notify_progress()
            return False
        
        # å¦‚æœç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
        if save_path.exists():
            try:
                shutil.rmtree(save_path)
            except Exception as e:
                self.progress.status = "error"
                self.progress.error_message = f"æ— æ³•åˆ é™¤æ—§ç›®å½•: {e}"
                self._notify_progress()
                return False
        
        # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.progress.current_file = f"æ­£åœ¨ä» ModelScope å…‹éš†æ¨¡å‹ (çº¦18GB)..."
        self._notify_progress()
        print(f"ğŸ“¥ æ‰§è¡Œ: git clone {self.MODELSCOPE_GIT_URL}")
        
        try:
            # ä½¿ç”¨ git clone ä¸‹è½½
            process = subprocess.Popen(
                ['git', 'clone', self.MODELSCOPE_GIT_URL, str(save_path)],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0,
                cwd=str(save_path.parent)
            )
            
            # å®æ—¶è¯»å–è¾“å‡º
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                if line:
                    line = line.strip()
                    if line:
                        # è§£æ git è¿›åº¦ä¿¡æ¯
                        if 'Receiving objects:' in line or 'Resolving deltas:' in line:
                            self.progress.current_file = line
                            self._notify_progress()
                        elif '%' in line:
                            self.progress.current_file = line
                            self._notify_progress()
                        print(line)
            
            if process.returncode == 0:
                self.progress.current_file = "âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ!"
                self._notify_progress()
                print("âœ… Git clone æˆåŠŸ")
                return True
            else:
                self.progress.status = "error"
                self.progress.error_message = f"Git clone å¤±è´¥ï¼Œè¿”å›ç : {process.returncode}"
                self._notify_progress()
                return False
                
        except Exception as e:
            self.progress.status = "error"
            self.progress.error_message = f"Git clone å¼‚å¸¸: {str(e)}"
            self._notify_progress()
            return False
            
    def download_model_async(self, model_name: str,
                             progress_callback: Optional[Callable[[DownloadProgress], None]] = None,
                             use_mirror: bool = True):
        """å¼‚æ­¥ä¸‹è½½æ¨¡å‹"""
        self._download_thread = threading.Thread(
            target=self.download_model,
            args=(model_name, progress_callback, use_mirror),
            daemon=True
        )
        self._download_thread.start()
        
    def stop_download(self):
        """åœæ­¢ä¸‹è½½"""
        self._stop_flag = True
        if self._download_thread and self._download_thread.is_alive():
            self._download_thread.join(timeout=5)
            
    def _notify_progress(self):
        """é€šçŸ¥è¿›åº¦æ›´æ–°"""
        if self._progress_callback:
            try:
                self._progress_callback(self.progress)
            except Exception:
                pass
            
    def delete_model(self, model_name: str) -> bool:
        """åˆ é™¤å·²ä¸‹è½½çš„æ¨¡å‹"""
        import shutil
        
        model_path = self.get_model_path(model_name)
        if model_path.exists():
            try:
                shutil.rmtree(model_path)
                return True
            except Exception:
                return False
        return True
        
    def get_model_size(self, model_name: str) -> int:
        """è·å–æ¨¡å‹å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        model_path = self.get_model_path(model_name)
        if not model_path.exists():
            return 0
            
        total_size = 0
        for f in model_path.rglob('*'):
            if f.is_file():
                total_size += f.stat().st_size
        return total_size


class VLLMServerManager:
    """vLLMæœåŠ¡ç®¡ç†å™¨"""
    
    def __init__(self, model_path: str, port: int = 8000):
        self.model_path = model_path
        self.port = port
        self.process: Optional[object] = None
        self._is_running = False
        self._startup_timeout = 30  # å¯åŠ¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
    def start(self, gpu_memory_utilization: float = 0.9,
              max_model_len: int = 8192) -> bool:
        """å¯åŠ¨vLLMæœåŠ¡"""
        try:
            import subprocess
            import requests
            
            # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not Path(self.model_path).exists():
                print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
                return False
            
            cmd = [
                sys.executable, '-m', 'vllm.entrypoints.openai.api_server',
                '--model', self.model_path,
                '--port', str(self.port),
                '--gpu-memory-utilization', str(gpu_memory_utilization),
                '--max-model-len', str(max_model_len),
                '--trust-remote-code',
            ]
            
            print(f"ğŸ“ å¯åŠ¨å‘½ä»¤: {' '.join(cmd)}")
            
            self.process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0
            )
            
            print(f"â³ ç­‰å¾…vLLMæœåŠ¡å¯åŠ¨ (æœ€å¤š{self._startup_timeout}ç§’)...")
            
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ç«‹å³å´©æºƒ
            time.sleep(2)
            if self.process.poll() is not None:
                stderr = self.process.stderr.read() if self.process.stderr else ""
                stdout = self.process.stdout.read() if self.process.stdout else ""
                error_msg = f"è¿›ç¨‹ç«‹å³é€€å‡º\nSTDOUT: {stdout}\nSTDERR: {stderr}"
                print(f"âŒ {error_msg}")
                return False
            
            # è½®è¯¢æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯åŠ¨
            for attempt in range(self._startup_timeout):
                try:
                    response = requests.get(f"http://localhost:{self.port}/v1/models", timeout=2)
                    if response.status_code == 200:
                        print(f"âœ… vLLMæœåŠ¡å·²å¯åŠ¨ (è€—æ—¶{attempt}ç§’)")
                        self._is_running = True
                        return True
                except Exception:
                    pass
                
                time.sleep(1)
                
                # å†æ¬¡æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                if self.process.poll() is not None:
                    stderr = self.process.stderr.read() if self.process.stderr else ""
                    stdout = self.process.stdout.read() if self.process.stdout else ""
                    error_msg = f"å¯åŠ¨è¿‡ç¨‹ä¸­è¿›ç¨‹é€€å‡º\nSTDOUT: {stdout}\nSTDERR: {stderr}"
                    print(f"âŒ {error_msg}")
                    return False
            
            print(f"âŒ å¯åŠ¨è¶…æ—¶({self._startup_timeout}ç§’)ï¼ŒæœåŠ¡æœªå“åº”")
            self.stop()
            return False
                
        except ImportError as e:
            print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
            print("è¯·å®‰è£…: pip install vllm requests")
            return False
        except Exception as e:
            print(f"âŒ å¯åŠ¨vLLMæœåŠ¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
            
    def stop(self):
        """åœæ­¢vLLMæœåŠ¡"""
        if self.process:
            try:
                if self.process.poll() is None:  # è¿›ç¨‹ä»åœ¨è¿è¡Œ
                    self.process.terminate()
                    try:
                        self.process.wait(timeout=10)
                    except subprocess.TimeoutExpired:
                        print("âš ï¸  è¿›ç¨‹æœªåœ¨è§„å®šæ—¶é—´å†…åœæ­¢ï¼Œå¼ºåˆ¶æ€æ­»...")
                        self.process.kill()
                        self.process.wait()
            except Exception as e:
                print(f"âš ï¸  åœæ­¢è¿›ç¨‹æ—¶å‡ºé”™: {e}")
            finally:
                self.process = None
        self._is_running = False
        print("âœ… vLLMæœåŠ¡å·²åœæ­¢")
        
    def is_running(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œä¸­"""
        if self.process is None:
            return False
        
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œ
        poll_result = self.process.poll()
        if poll_result is not None:
            self._is_running = False
            return False
        
        # å°è¯•ping APIæ£€æŸ¥æ˜¯å¦çœŸæ­£å¯ç”¨
        try:
            import requests
            response = requests.get(f"http://localhost:{self.port}/v1/models", timeout=2)
            return response.status_code == 200
        except Exception:
            return False
        
    def get_api_base(self) -> str:
        """è·å–APIåŸºç¡€URL"""
        return f"http://localhost:{self.port}/v1"


if __name__ == '__main__':
    # æµ‹è¯•ä¸‹è½½å™¨
    downloader = ModelDownloader()
    
    print("å¯ç”¨æ¨¡å‹:")
    for name, info in downloader.AVAILABLE_MODELS.items():
        print(f"  - {name}: {info.description}")
        
    print(f"\nå·²ä¸‹è½½æ¨¡å‹: {downloader.get_downloaded_models()}")
